# -*- coding: utf-8 -*-
"""SCT_ML_Task1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HJRN7BlLDOQ1wMRbhKI1H0C3SRTl3vEh
"""

# Install Kaggle CLI and joblib for saving model
!pip install -q kaggle joblib

from google.colab import files
print("Please upload your kaggle.json file (downloaded from Kaggle).")
uploaded = files.upload()  # select kaggle.json

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls -lah ~/.kaggle

# Download the competition dataset (train.csv, test.csv, data_description.txt)
!kaggle competitions download -c house-prices-advanced-regression-techniques -p /content
# Unzip files into /content
!unzip -o /content/house-prices-advanced-regression-techniques.zip -d /content
# List files to verify
!ls -lah /content | sed -n '1,200p'

import pandas as pd
df = pd.read_csv('/content/train.csv')
print("Shape:", df.shape)
df.head()

columns_to_check = ['Id','GrLivArea','BedroomAbvGr','FullBath','HalfBath','SalePrice']
print(df[columns_to_check].head(10).to_string(index=False))

# Build a clean DataFrame: sqft, bedrooms, bathrooms, price
df2 = df[['GrLivArea','BedroomAbvGr','FullBath','HalfBath','SalePrice']].copy()

# Combine baths: FullBath + 0.5*HalfBath
df2['bathrooms'] = df2['FullBath'] + 0.5 * df2['HalfBath']

# Rename columns
df2 = df2.rename(columns={'GrLivArea':'sqft','BedroomAbvGr':'bedrooms','SalePrice':'price'})

# Select final columns and drop NA if any (should be minimal)
df2 = df2[['sqft','bedrooms','bathrooms','price']].dropna().reset_index(drop=True)
print("Final shape:", df2.shape)
df2.head()

df2.describe().T

# Quick visualization for outliers
import matplotlib.pyplot as plt
plt.figure(figsize=(9,4))
plt.subplot(1,2,1)
plt.scatter(df2['sqft'], df2['price'], alpha=0.4)
plt.xlabel('sqft'); plt.ylabel('price'); plt.title('Price vs Sqft')

plt.subplot(1,2,2)
plt.boxplot(df2['sqft'], vert=False)
plt.title('Boxplot of sqft')
plt.show()

# Remove top 1% by sqft to reduce skew (optional)
q99 = df2['sqft'].quantile(0.99)
print("99th percentile sqft:", q99)
df_clean = df2[df2['sqft'] <= q99].reset_index(drop=True)
print("Shape before:", df2.shape, "after removing top 1% sqft:", df_clean.shape)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
import numpy as np

# Choose dataset to use:
data = df_clean if 'df_clean' in globals() else df2

X = data[['sqft','bedrooms','bathrooms']].values
y = data['price'].values

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42
)

model = LinearRegression()
model.fit(X_train, y_train)

print("Trained LinearRegression.")
print("Intercept:", model.intercept_)
print("Coefficients:", dict(zip(['sqft','bedrooms','bathrooms'], model.coef_)))

from sklearn.metrics import mean_squared_error, r2_score

y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"MSE: {mse:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"R^2: {r2:.4f}")

import matplotlib.pyplot as plt
plt.figure(figsize=(7,6))
plt.scatter(y_test, y_pred, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel('Actual Price')
plt.ylabel('Predicted Price')
plt.title('Actual vs Predicted - Linear Regression')
plt.grid(True)
plt.savefig('/content/actual_vs_predicted_lr.png', bbox_inches='tight')
plt.show()
print("Saved plot to /content/actual_vs_predicted_lr.png")

import joblib
import pandas as pd

pred_df = pd.DataFrame(X_test, columns=['sqft','bedrooms','bathrooms'])
pred_df['actual_price'] = y_test
pred_df['predicted_price'] = np.round(y_pred,2)
pred_csv_path = '/content/predictions_lr.csv'
pred_df.to_csv(pred_csv_path, index=False)
print("Saved predictions CSV:", pred_csv_path)

model_path = '/content/linear_reg_model_lr.joblib'
joblib.dump(model, model_path)
print("Saved model file:", model_path)

# Log-transform target to reduce skew, train again
data2 = data.copy()
data2['log_price'] = np.log(data2['price'])

X = data2[['sqft','bedrooms','bathrooms']].values
y_log = data2['log_price'].values

X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.20, random_state=42)

model_log = LinearRegression()
model_log.fit(X_train, y_train_log)
y_pred_log = model_log.predict(X_test)
# convert back
y_pred_transformed = np.exp(y_pred_log)
y_test_transformed = np.exp(y_test_log)

from sklearn.metrics import mean_squared_error, r2_score
mse_log = mean_squared_error(y_test_transformed, y_pred_transformed)
rmse_log = np.sqrt(mse_log)
r2_log = r2_score(y_test_transformed, y_pred_transformed)

print("Log-target model results (back-transformed):")
print(f"RMSE: {rmse_log:.2f}, R^2: {r2_log:.4f}")
# Save this model too
joblib.dump(model_log, '/content/linear_reg_model_log.joblib')
print("Saved log-transformed model to /content/linear_reg_model_log.joblib")

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
rf.fit(X_train, np.exp(y_train_log) if 'y_train_log' in globals() else y_train)
y_pred_rf = rf.predict(X_test)
mse_rf = mean_squared_error(y_test if 'y_test' in globals() else np.exp(y_test_log), y_pred_rf)
rmse_rf = np.sqrt(mse_rf); r2_rf = r2_score(y_test if 'y_test' in globals() else np.exp(y_test_log), y_pred_rf)
print(f"Random Forest RMSE: {rmse_rf:.2f}, R^2: {r2_rf:.4f}")
joblib.dump(rf, '/content/random_forest_model.joblib')
print("Saved random forest model to /content/random_forest_model.joblib")

from google.colab import files
files.download('/content/predictions_lr.csv')            # predictions csv
files.download('/content/actual_vs_predicted_lr.png')    # plot
files.download('/content/linear_reg_model_lr.joblib')    # linear model
files.download('/content/linear_reg_model_log.joblib')   # log model (if created)
files.download('/content/random_forest_model.joblib')    # rf model (if created)